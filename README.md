# EvaluaciÃ³n 1 - Scraping de Noticias y SerializaciÃ³n en JSONL

## ğŸ“Œ Fuente seleccionada
- **BBC Mundo** (https://www.bbc.com/mundo)  
Elegida por su facilidad de acceso y estructura HTML estable.

## ğŸ“‚ Flujo de AdquisiciÃ³n de Datos
1. **Scraping** con `src/scraper.py`.  
2. **SerializaciÃ³n** en `data/raw/noticias.jsonl`.  
3. **Perfilado de calidad** en `reports/perfilado.md`.  
4. **DefiniciÃ³n de contrato de datos** en `contracts/schema.yaml`.

## âš™ï¸ EjecuciÃ³n
```bash
python src/scraper.py
```

## ğŸ“Š Archivos entregables
- `src/scraper.py` â†’ cÃ³digo de scraping.  
- `data/raw/noticias.jsonl` â†’ noticias extraÃ­das.  
- `contracts/schema.yaml` â†’ contrato de datos.  
- `reports/perfilado.md` â†’ reporte de calidad.  
- `README.md` â†’ documentaciÃ³n.  

## ğŸš§ Problemas encontrados
- BBC Mundo no siempre expone fecha ni autor en portada.  
- Se requiere extraer fecha del HTML interno de cada noticia si se quiere mayor calidad.  
